{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 95 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   sepal_length_cm  95 non-null     float64\n",
      " 1   sepal_width_cm   95 non-null     float64\n",
      " 2   petal_length_cm  95 non-null     float64\n",
      " 3   petal_width_cm   95 non-null     float64\n",
      " 4   class            95 non-null     object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 4.5+ KB\n",
      "1 . Loss: 0.6141974112728121 , W: [-0.04773024  0.19680973 -0.27644736 -0.27860205 -0.01285647]\n",
      "2 . Loss: 0.3812040356581473 , W: [-0.07567639  0.32674729 -0.46398295 -0.46774688 -0.02563349]\n",
      "3 . Loss: 0.27025497793655195 , W: [-0.09318175  0.42005285 -0.60160829 -0.6066262  -0.03743004]\n",
      "4 . Loss: 0.20838080853515162 , W: [-0.104927    0.49192295 -0.70939404 -0.71540785 -0.04799567]\n",
      "5 . Loss: 0.1694546655085359 , W: [-0.1132375   0.55003559 -0.79774021 -0.80455956 -0.05742033]\n",
      "6 . Loss: 0.14283499948695957 , W: [-0.11935931  0.59865066 -0.87252478 -0.88000643 -0.06586433]\n",
      "7 . Loss: 0.12351934492624092 , W: [-0.12401129  0.64034196 -0.93734584 -0.94537949 -0.07348068]\n",
      "8 . Loss: 0.10887580949929898 , W: [-0.12763424  0.67677336 -0.99455123 -1.00305005 -0.08039856]\n",
      "9 . Loss: 0.0973955686055912 , W: [-0.13051221  0.70907899 -1.04575236 -1.05464663 -0.08672344]\n",
      "10 . Loss: 0.08815413803148094 , W: [-0.13283576  0.73806516 -1.09210083 -1.10133365 -0.09254077]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.13283576,  0.73806516, -1.09210083, -1.10133365, -0.09254077])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('data/iris-data.csv')\n",
    "df = df.dropna()\n",
    "df.info()\n",
    "\n",
    "df['class'].replace([\"Iris-setosa\", \"Iris-versicolor\"], [1, 0], inplace=True)\n",
    "\n",
    "inp_df = df.drop(df.columns[[4]], axis=1)  #here axis 1 for column\n",
    "out_df = df.drop(df.columns[[0, 1, 2, 3]], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "inp_df = scaler.fit_transform(inp_df)\n",
    "\n",
    "new_c = (np.zeros(shape=(inp_df.shape[0], 1)) + 1)\n",
    "inp_df = np.concatenate((inp_df, new_c), axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inp_df, out_df, test_size=0.2, random_state=42)\n",
    "\n",
    "def model(X, W):\n",
    "    # Logistic regression model implementation\n",
    "    z = np.dot(X, W)\n",
    "    y = 1 / (1 + np.exp(-z))\n",
    "    return y\n",
    "\n",
    "def loss_bce(y_true, y_pred):\n",
    "    # Binary cross entropy loss\n",
    "    n_samples = y_true.shape[0]\n",
    "    loss = -np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)) / n_samples\n",
    "    return loss\n",
    "\n",
    "def fit(num_weights, epoch=10, lr=0.01, batch_size=32):\n",
    "    # Initialization\n",
    "    W = np.zeros(num_weights)\n",
    "\n",
    "    # Epochs start\n",
    "    for e in range(1, epoch + 1):\n",
    "        total_loss = 0.0\n",
    "        num_batches = X_train.shape[0] // batch_size\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            start = batch * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            X_batch = X_train[start:end]\n",
    "            y_batch = y_train.iloc[start:end].values.flatten()  # Convert y_batch to a flattened array\n",
    "\n",
    "            y_pred = model(X_batch, W)\n",
    "            loss = loss_bce(y_batch, y_pred)\n",
    "            total_loss += loss\n",
    "\n",
    "            for j in range(W.shape[0]):\n",
    "                # Calculate derivative against parameters\n",
    "                dw_j = np.dot(X_batch[:, j], (y_pred - y_batch))\n",
    "                # Update parameters\n",
    "                W[j] = W[j] - lr * dw_j\n",
    "\n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(e, \". Loss:\", avg_loss, \", W:\", W)\n",
    "\n",
    "    return W\n",
    "\n",
    "fit(5, epoch=10, lr=0.01, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    class\n",
      "71      0\n",
      "20      1\n",
      "83      0\n",
      "84      0\n",
      "35      1\n",
      "..    ...\n",
      "65      0\n",
      "76      0\n",
      "19      1\n",
      "97      0\n",
      "56      0\n",
      "\n",
      "[76 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
